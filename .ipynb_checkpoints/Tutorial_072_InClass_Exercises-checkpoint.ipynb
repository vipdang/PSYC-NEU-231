{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In class exercise...\n",
    "* MI is biased in that small sample sizes lead to inaccurate estimates of PDFs, and that can sometimes lead to negative MI values (which should never happen in theory). \n",
    "* A common, and simple, approach, is to compute MI with shuffled condition labels (like randomization tests that we did many weeks back) and then subtract the shuffled MI from the actual MI. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KernelDensity\n",
    "# also define the default font we'll use for figures. \n",
    "fig_font = {'fontname':'Arial', 'size':'20'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First set up two arrays of data...make them correlated to some degree so that there is a reasonably high MI..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1.\n",
      " 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0.\n",
      " 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1.\n",
      " 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1.\n",
      " 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1.\n",
      " 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1.\n",
      " 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1.\n",
      " 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1.\n",
      " 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1.\n",
      " 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0.\n",
      " 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0.\n",
      " 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1.\n",
      " 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1.\n",
      " 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0.\n",
      " 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1.\n",
      " 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
      " 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "#make np.rand of 0s and 1s\n",
    "#make another np.rand of 0s and 1s but replace half of them with just 0s and 1s\n",
    "\n",
    "N=1000\n",
    "z = np.random.choice(N,int(N/2),replace=0)\n",
    "x = np.round(np.random.rand(N))\n",
    "y = np.round(np.random.rand(N))\n",
    "y[z] = x[z]\n",
    "print(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then compute the MI between the arrays. Can do two discrete arrays for simplicity, and import the entropy and conditional entropy functions from the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16910870474255346\n"
     ]
    }
   ],
   "source": [
    "# MI = Hx - Hyx\n",
    "\n",
    "def entropy(x):\n",
    "    \"\"\"compute entropy of discrete array x\n",
    "\n",
    "    Args:\n",
    "        x (int): array of discrete values\n",
    "\n",
    "    Returns:\n",
    "        Hx (float): entropy of x\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    uniquex = np.unique(x)\n",
    "\n",
    "    Hx = 0\n",
    "    for i in np.arange(len(uniquex)):\n",
    "        px = np.sum(x==uniquex[i])/len(x)    \n",
    "        if px!=0:\n",
    "            Hx += (-np.sum( px * np.log2(px) ))  \n",
    "        else:\n",
    "            print('px is zero for value ', i)\n",
    "        \n",
    "    return Hx\n",
    "\n",
    "\n",
    "def condEntropy(x,y):\n",
    "    \n",
    "    \"\"\"\n",
    "    conditional entropy, or the average entropy of x given each y, or Hxy\n",
    "    1) For all Y {i=1:numel(X)}, compute the entropy of X given each Y\n",
    "    2) Multiply H(X|Y==i) with the probability of each Y (i.e. pxi)\n",
    "    3) Sum over all i\n",
    "\n",
    "    Args:\n",
    "        x (int): array of discrete values\n",
    "        y (int): array of discrete values\n",
    "        \n",
    "    Returns:\n",
    "        Hxy (float): average conditional entropy of x given y\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Hxy=0\n",
    "    uniquex = np.unique(x)\n",
    "    uniquey = np.unique(y)\n",
    "    \n",
    "    for i in np.arange(len(uniquey)): \n",
    "        py = np.sum(y==uniquey[i]) / N\n",
    "        tmp=0\n",
    "        for j in np.arange(len(uniquex)):\n",
    "            px_y = np.sum((x==uniquex[j]) & (y==uniquey[i])) / np.sum(y==uniquey[i])    \n",
    "            tmp += (-( px_y * np.log2(px_y) ))                                     \n",
    "\n",
    "        Hxy += py*tmp\n",
    "\n",
    "    return Hxy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now repeat the above operations, but shuffle the data arrays and repeat the analysis many times (~500-1000 times). Plot the distribution of MI values that you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20203600659441645\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEhZJREFUeJzt3X+sZGd93/H3p7v+FUOxiS9os7vKmnSbxETN2ro1bl1Frk2LbSKWSKUyUoKLXG2qmgraqI1JpAaqWiJqEkdIratN7LCkxGZroKyI2+I4IIIibK7N2uyyuCz2Bl92670JYHBRndh8+8c82wyb671z5wd38PN+SUdz5jnPOfOduTufOfOcc2ZTVUiS+vHXNroASdL3lsEvSZ0x+CWpMwa/JHXG4Jekzhj8ktQZg1+SOmPwS1JnDH5J6szmjS4A4KKLLqodO3ZsdBmS9H3loYce+tOqWljvenMR/Dt27GBpaWmjy5Ck7ytJ/mSc9dYc6klybpIHkzyS5HCSd7f29yV5IsnBNu1q7Uny3iRHkzya5LJxCpMkzcYoe/zPAldX1TNJzgI+neS/t2X/uqruOa3/dcDONr0GuL3dSpLmwJp7/DXwTLt7VpvO9JOeu4H3t/U+A1yQZMvkpUqSpmGks3qSbEpyEDgJ3FdVD7RFt7bhnNuSnNPatgJPDq2+3NpO3+aeJEtJllZWViZ4CpKk9Rgp+Kvq+araBWwDLk/yE8A7gR8D/jbwcuAXW/estolVtrm3qharanFhYd0HpSVJY1rXefxV9Q3gk8C1VXWiDec8C/wOcHnrtgxsH1ptG3B8CrVKkqZglLN6FpJc0ObPA14LfPHUuH2SAG8EDrVVDgBvaWf3XAE8XVUnZlK9JGndRjmrZwuwL8kmBh8U+6vqY0n+MMkCg6Gdg8A/a/3vBa4HjgLfBt46/bIlSeNaM/ir6lHg0lXar36B/gXcPHlpkqRZmIsrdyex45bf37DHPvae12/YY0vSuPyRNknqjMEvSZ0x+CWpMwa/JHXG4Jekzhj8ktQZg1+SOmPwS1JnDH5J6ozBL0mdMfglqTMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZwx+SeqMwS9JnTH4JakzBr8kdWbN4E9ybpIHkzyS5HCSd7f2i5M8kORLST6Y5OzWfk67f7Qt3zHbpyBJWo9R9vifBa6uqp8EdgHXJrkC+FXgtqraCXwduKn1vwn4elX9DeC21k+SNCfWDP4aeKbdPatNBVwN3NPa9wFvbPO7233a8muSZGoVS5ImMtIYf5JNSQ4CJ4H7gC8D36iq51qXZWBrm98KPAnQlj8N/OA0i5YkjW+k4K+q56tqF7ANuBz48dW6tdvV9u7r9IYke5IsJVlaWVkZtV5J0oTWdVZPVX0D+CRwBXBBks1t0TbgeJtfBrYDtOUvA762yrb2VtViVS0uLCyMV70kad1GOatnIckFbf484LXAEeATwD9q3W4EPtrmD7T7tOV/WFV/ZY9fkrQxNq/dhS3AviSbGHxQ7K+qjyX5AnB3kn8PfA64o/W/A/jdJEcZ7OnfMIO6JUljWjP4q+pR4NJV2h9nMN5/evv/Bd40leokSVPnlbuS1BmDX5I6Y/BLUmcMfknqjMEvSZ0x+CWpMwa/JHXG4Jekzhj8ktQZg1+SOmPwS1JnDH5J6ozBL0mdMfglqTMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZwx+SeqMwS9JnVkz+JNsT/KJJEeSHE7y9tb+riRfTXKwTdcPrfPOJEeTPJbkdbN8ApKk9dk8Qp/ngF+oqoeTvBR4KMl9bdltVfVrw52TXALcALwa+CHgD5L8zap6fpqFS5LGs+Yef1WdqKqH2/y3gCPA1jOsshu4u6qeraongKPA5dMoVpI0uXWN8SfZAVwKPNCa3pbk0SR3JrmwtW0FnhxabZkzf1BIkr6HRg7+JC8BPgS8o6q+CdwO/AiwCzgB/PqprqusXqtsb0+SpSRLKysr6y5ckjSekYI/yVkMQv8DVfVhgKp6qqqer6rvAL/FXw7nLAPbh1bfBhw/fZtVtbeqFqtqcWFhYZLnIElah1HO6glwB3Ckqn5jqH3LULefAQ61+QPADUnOSXIxsBN4cHolS5ImMcpZPVcCPwd8PsnB1vZLwJuT7GIwjHMM+HmAqjqcZD/wBQZnBN3sGT2SND/WDP6q+jSrj9vfe4Z1bgVunaAuSdKMeOWuJHXG4Jekzhj8ktQZg1+SOmPwS1JnDH5J6ozBL0mdMfglqTMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZwx+SeqMwS9JnTH4JakzBr8kdcbgl6TOGPyS1BmDX5I6Y/BLUmcMfknqzJrBn2R7kk8kOZLkcJK3t/aXJ7kvyZfa7YWtPUnem+RokkeTXDbrJyFJGt0oe/zPAb9QVT8OXAHcnOQS4Bbg/qraCdzf7gNcB+xs0x7g9qlXLUka25rBX1UnqurhNv8t4AiwFdgN7Gvd9gFvbPO7gffXwGeAC5JsmXrlkqSxrGuMP8kO4FLgAeCVVXUCBh8OwCtat63Ak0OrLbe207e1J8lSkqWVlZX1Vy5JGsvIwZ/kJcCHgHdU1TfP1HWVtvorDVV7q2qxqhYXFhZGLUOSNKGRgj/JWQxC/wNV9eHW/NSpIZx2e7K1LwPbh1bfBhyfTrmSpEmNclZPgDuAI1X1G0OLDgA3tvkbgY8Otb+lnd1zBfD0qSEhSdLG2zxCnyuBnwM+n+Rga/sl4D3A/iQ3AV8B3tSW3QtcDxwFvg28daoVS5ImsmbwV9WnWX3cHuCaVfoXcPOEdUmSZsQrdyWpMwa/JHXG4Jekzhj8ktQZg1+SOmPwS1JnDH5J6ozBL0mdMfglqTMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZwx+SeqMwS9JnTH4JakzBr8kdcbgl6TOGPyS1BmDX5I6s2bwJ7kzyckkh4ba3pXkq0kOtun6oWXvTHI0yWNJXjerwiVJ4xllj/99wLWrtN9WVbvadC9AkkuAG4BXt3X+U5JN0ypWkjS5NYO/qj4FfG3E7e0G7q6qZ6vqCeAocPkE9UmSpmySMf63JXm0DQVd2Nq2Ak8O9VlubZKkOTFu8N8O/AiwCzgB/Hprzyp9a7UNJNmTZCnJ0srKyphlSJLWa6zgr6qnqur5qvoO8Fv85XDOMrB9qOs24PgLbGNvVS1W1eLCwsI4ZUiSxjBW8CfZMnT3Z4BTZ/wcAG5Ick6Si4GdwIOTlShJmqbNa3VIchdwFXBRkmXgV4CrkuxiMIxzDPh5gKo6nGQ/8AXgOeDmqnp+NqVLksaxZvBX1ZtXab7jDP1vBW6dpChJ0ux45a4kdcbgl6TOGPyS1BmDX5I6Y/BLUmcMfknqjMEvSZ0x+CWpMwa/JHXG4Jekzhj8ktQZg1+SOmPwS1JnDH5J6ozBL0mdMfglqTMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZ9YM/iR3JjmZ5NBQ28uT3JfkS+32wtaeJO9NcjTJo0kum2XxkqT1G2WP/33Atae13QLcX1U7gfvbfYDrgJ1t2gPcPp0yJUnTsmbwV9WngK+d1rwb2Nfm9wFvHGp/fw18BrggyZZpFStJmty4Y/yvrKoTAO32Fa19K/DkUL/l1iZJmhPTPribVdpq1Y7JniRLSZZWVlamXIYk6YWMG/xPnRrCabcnW/sysH2o3zbg+GobqKq9VbVYVYsLCwtjliFJWq9xg/8AcGObvxH46FD7W9rZPVcAT58aEpIkzYfNa3VIchdwFXBRkmXgV4D3APuT3AR8BXhT634vcD1wFPg28NYZ1CxJmsCawV9Vb36BRdes0reAmyctSpI0O165K0mdMfglqTMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZwx+SeqMwS9JnTH4JakzBr8kdcbgl6TOGPyS1BmDX5I6s+bPMuuF7bjl9zfkcY+95/Ub8riSXhzc45ekzhj8ktQZg1+SOmPwS1JnDH5J6ozBL0mdMfglqTMTncef5BjwLeB54LmqWkzycuCDwA7gGPCPq+rrk5UpSZqWaezx//2q2lVVi+3+LcD9VbUTuL/dlyTNiVlcubsbuKrN7wM+CfziDB6nWxt1xTB41bD0YjDpHn8BH0/yUJI9re2VVXUCoN2+YrUVk+xJspRkaWVlZcIyJEmjmnSP/8qqOp7kFcB9Sb446opVtRfYC7C4uFgT1iFJGtFEe/xVdbzdngQ+AlwOPJVkC0C7PTlpkZKk6Rk7+JOcn+Slp+aBfwgcAg4AN7ZuNwIfnbRISdL0TDLU80rgI0lObef3qup/JPkssD/JTcBXgDdNXqYkaVrGDv6qehz4yVXa/wy4ZpKiJEmz45W7ktQZg1+SOmPwS1JnDH5J6ozBL0mdMfglqTMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZwx+SeqMwS9JnTH4Jakzs/jP1vUitlH/0bv/ybs0Pe7xS1JnDH5J6ozBL0mdcYxfWoPHNfRi4x6/JHXG4Jekzsws+JNcm+SxJEeT3DKrx5Ekrc9MxviTbAL+I/APgGXgs0kOVNUXZvF4evHbqHF26cVoVnv8lwNHq+rxqvpz4G5g94weS5K0DrM6q2cr8OTQ/WXgNTN6LElTtJHfrjbqTKbenvOsgj+rtNV3dUj2AHva3WeSPDbmY10E/OmY634vzHN91jae70lt+dWxVvu+ft3GfM7TsGGv2wjP+Uy1/fA4jzmr4F8Gtg/d3wYcH+5QVXuBvZM+UJKlqlqcdDuzMs/1Wdt4rG081jaeWdQ2qzH+zwI7k1yc5GzgBuDAjB5LkrQOM9njr6rnkrwN+J/AJuDOqjo8i8eSJK3PzH6yoaruBe6d1faHTDxcNGPzXJ+1jcfaxmNt45l6bamqtXtJkl40/MkGSerM3AX/Wj/1kOScJB9syx9IsmNo2Ttb+2NJXjfqNje4tjuTnExyaNy6ZlFbku1JPpHkSJLDSd4+R7Wdm+TBJI+02t49L7UNLduU5HNJPjZPtSU5luTzSQ4mWZqz2i5Ick+SL7Z/d39nXupL8qPtNTs1fTPJO+ahttb+L9t74VCSu5Kce8YiqmpuJgYHgr8MvAo4G3gEuOS0Pv8c+M9t/gbgg23+ktb/HODitp1No2xzo2pry34KuAw4NGev2xbgstbnpcD/mpfXjcF1Ii9pfc4CHgCumIfahtb7V8DvAR+bl79pW3YMuGje3qdt2T7gn7b5s4EL5qm+07b/v4EfnofaGFww+wRwXuu3H/gnZ6pj3vb4R/mph90M/oEA3ANckySt/e6qeraqngCOtu1N6+cjZlEbVfUp4Gtj1DPT2qrqRFU93Gr8FnCEwT+weaitquqZ1v+sNo1zsGomf9Mk24DXA789Rk0zrW1Kpl5bkr/OYCfoDoCq+vOq+sa81HfautcAX66qP5mj2jYD5yXZDPwAp103dbp5C/7Vfurh9LD5/32q6jngaeAHz7DuKNvcqNqmZaa1ta+alzLYs56L2tpQykHgJHBfVc1NbcBvAv8G+M4YNc26tgI+nuShDK6en5faXgWsAL/Thsh+O8n5c1TfsBuAu+altqr6KvBrwFeAE8DTVfXxMxUxb8G/5k89nKHPetvXaxa1TcvMakvyEuBDwDuq6pvzUltVPV9VuxhcFX55kp+Yh9qS/DRwsqoeGqOemdbWbq+sqsuA64Cbk/zUnNS2mcGQ5+1VdSnwf4Bxj8fN8v1wNvAG4L/OS21JLmTwbeBi4IeA85P87JmKmLfgX/OnHob7tK81L2MwVPJC646yzY2qbVpmUluSsxiE/geq6sPzVNspbTjgk8C1c1LblcAbkhxj8DX+6iT/ZU5qo6pO3Z4EPsJ4Q0Czep8uD31zu4fBB8E4Zvlv7jrg4ap6ao5qey3wRFWtVNVfAB8G/u4Zqxjn4MmsJgaf+o8z+OQ6deDj1af1uZnvPvCxv82/mu8+8PE4gwMfa25zo2obWm8Hkx3cncXrFuD9wG/O4d90gXbgDzgP+CPgp+ehttPWvYrxD+7O4nU7H3hp63M+8MfAtfNQW1v2R8CPtvl3Af9hXl67ofXuBt46Z++H1wCHGYzth8HxgX9xxjomeVPPYgKuZ3AGyZeBX25t/w54Q5s/l8HXrKPAg8Crhtb95bbeY8B1Z9rmHNV2F4Nxub9g8Il+0zzUBvw9Bl8vHwUOtun6OantbwGfa7UdAv7tPP1Nh5ZfxZjBP6PX7VUMguMRBkExb++FXcBS+7v+N+DCOavvB4A/A142bl0zrO3dwBfb++F3gXPOVINX7kpSZ+ZtjF+SNGMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZwx+SeqMwS9Jnfl/c+/9eSLraAwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N=1000\n",
    "z = np.random.choice(N,int(N/2),replace=0)\n",
    "x = np.round(np.random.rand(N))\n",
    "y = np.round(np.random.rand(N))\n",
    "y[z] = x[z]\n",
    "\n",
    "Hx1 = entropy(x=x)\n",
    "Hxy1 = condEntropy(x=x,y=y)\n",
    "MI1 = Hx1 - Hxy1\n",
    "print(MI1)\n",
    "\n",
    "b = np.zeros(500)\n",
    "\n",
    "for i in range(500):\n",
    "    np.random.shuffle(y)\n",
    "    Hx = entropy(x=x)\n",
    "    Hxy = condEntropy(x=x,y=y)\n",
    "    MI = Hx - Hxy\n",
    "    b[i] = MI\n",
    "# y[z] = x[z]\n",
    "# print(y)\n",
    "# print(x)\n",
    "\n",
    "plt.hist(b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now subtract the mean of the shuffled MI values from your 'real' MI value...this will help correct for any bias that is introduced by a limited sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20122697219127286\n"
     ]
    }
   ],
   "source": [
    "q = MI1-np.mean(b)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
